{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab55f47-7dda-40a2-b89e-f6d307655188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous chargeons les packages nécessaires\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1042b674-e131-4435-bb3a-3b0e2bd4b04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DUPERSID                    7598\n",
       "EDUCYR                      7598\n",
       "TTLP22X                     7598\n",
       "FAMINC22                    7598\n",
       "AGE22X                      7598\n",
       "TOTEXP22                    7598\n",
       "TOTEXP23                    7570\n",
       "exp_dental_1                 598\n",
       "exp_dental_3                 740\n",
       "exp_dental_5                 562\n",
       "exp_dental_7                 609\n",
       "exp_dental_9                 572\n",
       "exp_dental_10                529\n",
       "exp_dental_11                530\n",
       "exp_dental_12                570\n",
       "exp_dental_8                 730\n",
       "exp_dental_6                 619\n",
       "exp_dental_2                 621\n",
       "exp_dental_4                 540\n",
       "exp_dental_total            3560\n",
       "exp_hospitals_1              490\n",
       "exp_hospitals_2              490\n",
       "exp_hospitals_3              490\n",
       "exp_hospitals_4              490\n",
       "exp_hospitals_5              490\n",
       "exp_hospitals_6              490\n",
       "exp_hospitals_7              490\n",
       "exp_hospitals_8              490\n",
       "exp_hospitals_9              490\n",
       "exp_hospitals_10             490\n",
       "exp_hospitals_11             490\n",
       "exp_hospitals_12             490\n",
       "exp_hospitals_2022_total     490\n",
       "exp_hospitals_2021_total       1\n",
       "exp_outpatient_10            374\n",
       "exp_outpatient_3             383\n",
       "exp_outpatient_1             400\n",
       "exp_outpatient_2             351\n",
       "exp_outpatient_5             364\n",
       "exp_outpatient_12            375\n",
       "exp_outpatient_11            344\n",
       "exp_outpatient_8             426\n",
       "exp_outpatient_4             351\n",
       "exp_outpatient_9             388\n",
       "exp_outpatient_7             389\n",
       "exp_outpatient_6             393\n",
       "exp_outpatient_total        1970\n",
       "exp_office_4                1976\n",
       "exp_office_9                2070\n",
       "exp_office_1                2179\n",
       "exp_office_2                2082\n",
       "exp_office_3                2142\n",
       "exp_office_5                2016\n",
       "exp_office_6                2052\n",
       "exp_office_7                2070\n",
       "exp_office_8                2271\n",
       "exp_office_10               2023\n",
       "exp_office_11               1972\n",
       "exp_office_12               1918\n",
       "exp_office_total            5783\n",
       "exp_er_3                     106\n",
       "exp_er_9                     125\n",
       "exp_er_1                     123\n",
       "exp_er_10                    107\n",
       "exp_er_6                     111\n",
       "exp_er_5                     107\n",
       "exp_er_12                    119\n",
       "exp_er_4                      95\n",
       "exp_er_2                     128\n",
       "exp_er_8                     133\n",
       "exp_er_11                    137\n",
       "exp_er_7                     139\n",
       "exp_er_total                1069\n",
       "exp_home_1                   123\n",
       "exp_home_2                   125\n",
       "exp_home_3                   139\n",
       "exp_home_4                   141\n",
       "exp_home_5                   140\n",
       "exp_home_6                   136\n",
       "exp_home_7                   136\n",
       "exp_home_8                   143\n",
       "exp_home_9                   149\n",
       "exp_home_10                  146\n",
       "exp_home_11                  148\n",
       "exp_home_12                  152\n",
       "exp_home_total               303\n",
       "exp_others_1                2843\n",
       "exp_others_2                2843\n",
       "exp_others_3                2843\n",
       "exp_others_4                2843\n",
       "exp_others_5                2843\n",
       "exp_others_6                2843\n",
       "exp_others_7                2843\n",
       "exp_others_8                2843\n",
       "exp_others_9                2843\n",
       "exp_others_10               2843\n",
       "exp_others_11               2843\n",
       "exp_others_12               2843\n",
       "exp_others_total            2843\n",
       "exp_medicines_1             4845\n",
       "exp_medicines_2             4845\n",
       "exp_medicines_3             4845\n",
       "exp_medicines_4             4845\n",
       "exp_medicines_5             4845\n",
       "exp_medicines_6             4845\n",
       "exp_medicines_7             4845\n",
       "exp_medicines_8             4845\n",
       "exp_medicines_9             4845\n",
       "exp_medicines_10            4845\n",
       "exp_medicines_11            4845\n",
       "exp_medicines_12            4845\n",
       "exp_medicines_total         4845\n",
       "dep_janvier                 7598\n",
       "dep_fevrier                 7598\n",
       "dep_mars                    7598\n",
       "dep_avril                   7598\n",
       "dep_mai                     7598\n",
       "dep_juin                    7598\n",
       "dep_juillet                 7598\n",
       "dep_aout                    7598\n",
       "dep_sept                    7598\n",
       "dep_oct                     7598\n",
       "dep_nov                     7598\n",
       "dep_dec                     7598\n",
       "dep_3_mois                  7598\n",
       "dep_6_mois                  7598\n",
       "nbre_au_dessus_moyenne      7598\n",
       "tendance                    7598\n",
       "dep_max                     7598\n",
       "ep_aigue                    7598\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nous lisons le fichier all_expenses_clean créé précédemment avec python\n",
    "all_expenses_clean = pd.read_csv(\"all_expenses_clean.csv\", sep=\",\")\n",
    "\n",
    "# Nous vérifions quelles colonnes contiennent des valeurs manquantes\n",
    "pd.set_option('display.max_rows', None)#  option pour voir toutes les entrées de la Series\n",
    "all_expenses_clean.count()\n",
    "#pd.reset_option('display.max_rows') #nous supprimons l'option\n",
    "\n",
    "# Nous remarquons que les variables socio-démographiques et économiques ne contiennent pas de NA.\n",
    "# Le seules variables contenant des NA sont les dépenses par poste et seront donc remplacées par 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f8415c-d8ec-4ae0-96cb-3164687ab6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous créons une variable Profil donnant le profil de chaque individu au regard\n",
    "# de ses dépenses de santé en 2023\n",
    "# Cette variable constitura notre variable cible\n",
    "\n",
    "#On copie le dataframe pour éviter d'écraser ou mélanger les index (identifiants des lignes)\n",
    "df = all_expenses_clean.copy()\n",
    "\n",
    "#Nous trions les individus par coûts (dépenses de santé) en 2023\n",
    "df_ordonne = df.sort_values(by=\"TOTEXP23\").reset_index(drop=True)\n",
    "\n",
    "# Calcul de la part cumulée des dépenses\n",
    "df_ordonne[\"cum_cost_share\"] = df_ordonne[\"TOTEXP23\"].cumsum() / df_ordonne[\"TOTEXP23\"].sum()\n",
    "\n",
    "# Seuils\n",
    "seuils = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "# Fonction pour définir le profil\n",
    "def assign_bucket(cum_cost):\n",
    "    if cum_cost <= seuils[0]: # individu à coût faible\n",
    "        return 0\n",
    "    elif cum_cost <= seuils[2]: # individu à coût modéré\n",
    "        return 1\n",
    "    else:                     #individu à coût élevé\n",
    "        return 2\n",
    "\n",
    "#On applique la fonction assign_bucket à la colonne cum_cost_share de df_ordonne\n",
    "#pour créer la variable profil\n",
    "df_ordonne[\"profil\"] = df_ordonne[\"cum_cost_share\"].apply(assign_bucket)\n",
    "\n",
    "# Grâce à la commande .sort_index(), on revient à l'ordre donné par les index\n",
    "# pour que l'assignation de la nouvelle se fasse correctement\n",
    "all_expenses_clean[\"profil\"] = df_ordonne.sort_index()[\"profil\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cde57a7-34da-4433-80d6-5fbcda295162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'échnatillon d'entrainement contient: 5698 individus et 129 variables explicatives\n",
      "L'échantillon test contient : 1900 individus\n"
     ]
    }
   ],
   "source": [
    "#Préparation des données pour les algorithmes de machine learning\n",
    "\n",
    "##############################################################################\n",
    "####  Définition de la variable cible et des attributs              #########\n",
    "############################################################################\n",
    "\n",
    "df = all_expenses_clean.copy()\n",
    "\n",
    "# Variable cible : profil\n",
    "y = df[\"profil\"]\n",
    "\n",
    "# Variables explicatives\n",
    "X = df.drop([\n",
    "    \"TOTEXP23\",\n",
    "    \"profil\"\n",
    "], axis=1, errors=\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#####    Création des échantillons test et train                        #######\n",
    "###############################################################################\n",
    "\n",
    "#On sépare les données en deux échantillons train et test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    stratify=y,    # en cas de classification, cette option sert à conserver les mêmes prportions de chaque classe dans les échantillons d'entrainement et de test\n",
    "    random_state=42 #utile pour la reproductibilité\n",
    ")\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "print(\"L'échnatillon d'entrainement contient: {} individus et {} variables explicatives\".format(n_samples, n_features))\n",
    "print(\"L'échantillon test contient : {} individus\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272c53d2-7e26-4879-8501-697d6ee39ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous créons un transformeur preprocess pour prétraiter les données\n",
    "\n",
    "###############################################################################\n",
    "############              Preprocessing                               #########\n",
    "###############################################################################\n",
    "\n",
    "# Séparation des variables numériques et catégorielles pour le pipeline\n",
    "num_vars = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_vars = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "# Les variables numériques correspondent à des variables de santé:\n",
    "# nous choisissons donc d'attribuer la valeur 0 à leur valeurs manquantes\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0)),\n",
    "    #on utilise la transformation  (x-median)/ intervalle interquartile pour\n",
    "    #tenir compte de la distribution très asymétrique des données de sante\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# Il n'y a aucune valeur manquante parmi les variables catégorielles choisies\n",
    "# ce qui rend l'imputation facultative\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Not defined\")),\n",
    "#encodage des variables catégorielles sous forme d'indicatrices\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "#On assemble le prétatraitement des variables numériques et cétegorielles\n",
    "#dans un preprocesseur unique\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_vars),\n",
    "        (\"cat\", categorical_transformer, cat_vars)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21239b8-e78f-4a3d-9d9e-21e66b211108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Résultats XGBoost ===\n",
      "Meilleurs paramètres : {'xgb__colsample_bytree': 0.8, 'xgb__learning_rate': 0.3, 'xgb__max_depth': 7, 'xgb__n_estimators': 500, 'xgb__subsample': 1.0}\n",
      "Balanced Accuracy CV : 0.9929318710988358\n",
      "Accuracy test : 0.9967105263157895\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Encodage des labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Pipeline\n",
    "pipe_xgb = Pipeline([\n",
    "    ('preprocess', preproc),\n",
    "    ('xgb', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Grille\n",
    "parameters_xgb = {\n",
    "    'xgb__n_estimators': [200, 500],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'xgb__subsample': [0.6, 0.8, 1.0],\n",
    "    'xgb__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "clf_xgb = GridSearchCV(\n",
    "    estimator=pipe_xgb,\n",
    "    param_grid=parameters_xgb,\n",
    "    cv=5,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'     # <-- très important pour voir l'erreur réelle\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "clf_xgb.fit(X_train, y_train_enc)\n",
    "\n",
    "# Résultats\n",
    "print(\"=== Résultats XGBoost ===\")\n",
    "print(\"Meilleurs paramètres :\", clf_xgb.best_params_)\n",
    "print(\"Balanced Accuracy CV :\", clf_xgb.best_score_)\n",
    "print(\"Accuracy test :\", clf_xgb.score(X_test, y_test_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bdd98bf-08aa-4e2d-bcce-e26d72474d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes dans y_train : [0, 1, 2]\n",
      "Classes dans y_test  : [0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes dans y_train :\", sorted(set(y_train)))\n",
    "print(\"Classes dans y_test  :\", sorted(set(y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff50702-843b-4e3e-971e-6727d81b0906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Résultats Random Forest ===\n",
      "Meilleurs paramètres : {'rf__max_depth': None, 'rf__max_features': 0.5, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n",
      "Balanced Accuracy CV : 0.9985507246376812\n",
      "Accuracy test : 0.9978070175438596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Pipeline : prétraitement + Random Forest\n",
    "pipe_rf = Pipeline([\n",
    "    ('preprocess', preproc),\n",
    "    ('rf', RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Grille d'hyperparamètres pour Random Forest\n",
    "parameters_rf = {\n",
    "    'rf__n_estimators': [200, 500],          # nombre d'arbres\n",
    "    'rf__max_depth': [None, 10, 20],         # profondeur maximale\n",
    "    'rf__min_samples_split': [2, 5, 10],     # min d'échantillons pour un split\n",
    "    'rf__min_samples_leaf': [1, 2, 4],       # min d'échantillons par feuille\n",
    "    'rf__max_features': ['sqrt', 'log2', 0.5]  # nombre de features testés par split\n",
    "}\n",
    "\n",
    "# Grid Search : recherche des hyperparamètres par validation croisée\n",
    "clf_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=parameters_rf,\n",
    "    cv=5,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Résultats\n",
    "print(\"=== Résultats Random Forest ===\")\n",
    "print(\"Meilleurs paramètres :\", clf_rf.best_params_)\n",
    "print(\"Balanced Accuracy CV :\", clf_rf.best_score_)\n",
    "print(\"Accuracy test :\", clf_rf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9614c-cad8-4ba8-8f64-a4939f6ad404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
